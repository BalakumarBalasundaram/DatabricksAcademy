Data Engineer Learning Plan 
- Data Engineering with Databricks
Data Engineer Learning Plan 
- Advanced Data Engineering with Databricks
Data Analyst Learning Plan 
- Data Analysis with Databricks SQL
Machine Learning Practitioner Learning Plan 
- Scalable Machine Learning with Apache Spark
Machine Learning Practitioner Learning Plan 
- Machine Learning in Production
Platform Administrator Learning Plan
AWS Databricks Platform Architect Learning Plan
Azure Databricks Platform Architect Learning Plan
GCP Databricks Platform Architect Learning Plan


PLEASE NOTE: THIS PATH HAS BEEN UPDATED TO REFLECT THE LATEST UPDATES FROM DATABRICKS ACADEMY. IF YOU ARE LOOKING FOR APACHE SPARK PROGRAMMING CONTENT, PLEASE SEE THE APACHE SPARK DEVELOPER LEARNING PLAN.

 

Demonstrate your knowledge of data engineering on Databricks by earning the Databricks Certified Data Engineer Associate/Professional Certifications. This path consists of the following:

 

   Databricks Certified Data Engineer Associate Certification 

Data Engineering with Databricks*

Certification Overview Course for the Databricks Certified Data Engineer Associate Exam

Databricks Certified Data Engineer Associate Exam (available for $200 USD)
 

   Databricks Certified Data Engineer Professional Certification 

Advanced Data Engineering with Databricks

Certification Overview Course for the Databricks Certified Data Engineer Professional Exam 

Databricks Certified Data Engineer Professional Exam (available for $200 USD)
 

NOTE:-  The pre-requisite to the content within this learning plan is found in the Fundamentals of the Databricks Lakehouse Platform (V2) learning plan, which is available at the following links (or, you can find it in the DB001 Databricks Academy catalog).

 
Customers: Click here.

Partners:  Click here.

Microsoft: Click here.

 *This content is also available via the paid instructor-led training course, Data Engineering with Databricks. 

 

 

Data Engineering with Databricks
Welcome to Data Engineering with Databricks. This course (formerly Data Engineering with Databricks V3) prepares data professionals to leverage the Databricks Lakehouse Platform to productionalize ETL pipelines. Students will use Delta Live Tables to define and schedule pipelines that incrementally process new data from a variety of data sources into the Lakehouse. Students will also orchestrate tasks with Databricks Workflows and promote code with Databricks Repos. Learning objectives Use the Databricks Data Science and Engineering Workspace to perform common code development tasks in a data engineering workflow. Use Spark SQL or PySpark to extract data from a variety of sources, apply common cleaning transformations, and manipulate complex data with advanced functions. Define and schedule data pipelines that incrementally ingest and process data through multiple tables in the lakehouse using Delta Live Tables in Spark SQL or Python. Orchestrate data pipelines with Databricks Workflow Jobs and schedule dashboard updates to keep analytics up-to-date. Configure permissions in Unity Catalog to ensure that users have proper access to databases for analytics and dashboarding.  Prerequisites Prerequisites for both versions of this course (Spark SQL and PySpark): Beginner familiarity with cloud computing concepts (virtual machines, object storage, etc.) Production experience working with data warehouses and data lakes Familiarity with basic SQL concepts (select, filter, groupby, join, etc) Additional prerequisites for the Python version of this course (PySpark): Beginner programming experience with Python (syntax, conditions, loops, functions) Beginner programming experience with the Spark DataFrame API: Configure DataFrameReader and DataFrameWriter to read and write data Express query transformations using DataFrame methods and Column expressions Navigate the Spark documentation to identify built-in functions for various transformations and data types The PySpark programming skills required for the Python version of this course can be learned by taking the Get Started with PySpark Programming course by Databricks Academy. Last course update October 2023  
E-Learning Duration: 12h
Exam Information: Databricks Certified Associate Data Engineer (available for additional fee)
For information about this exam, please click here.
E-Learning Duration: 1m
Advanced Data Engineering with Databricks
Welcome to the Advanced Data Engineering with Databricks course. This course is part of the Databricks Data Engineer learning pathway and was designed to help you prepare for the Databricks Certified Data Engineer Professional Certification exam.  In this course, students will build upon their existing knowledge of Apache Spark, Structured Streaming, and Delta Lake to unlock the full potential of the data lakehouse by utilizing the suite of tools provided by Databricks. This course places a heavy emphasis on designs favoring incremental data processing, enabling systems optimized to continuously ingest and analyze ever-growing data. By designing workloads that leverage built-in platform optimizations, data engineers can reduce the burden of code maintenance and on-call emergencies, and quickly adapt production code to new demands with minimal refactoring or downtime. The topics in this course should be mastered prior to attempting the Databricks Certified s Data Engineering Professional exam.  Learning objectives Design databases and pipelines optimized for the Databricks Lakehouse Platform. Implement efficient incremental data processing to validate and enrich data driving business decisions and applications. Leverage Databricks-native features for managing access to sensitive data and fulfilling right-to-be-forgotten requests. Manage code promotion, task orchestration, and production job monitoring using Databricks tools. Prerequisites Experience using PySpark APIs to perform advanced data transformations Familiarity implementing classes with Python Experience using SQL in production data warehouse or data lake implementations Experience working in Databricks notebooks and configuring clusters Familiarity with creating and manipulating data in Delta Lake tables with SQL Ability to use Spark Structured Streaming to incrementally read from a Delta table Learning path This course is part of the data engineering learning path.  Last course update July 2022
E-Learning Duration: 12h
Certification Overview: Databricks Certified Data Engineer Professional Exam
This course will cover the format and structure of the exam, topics assessed by the exam, example questions, and tips for exam preparation. Learning objectives Describe the learning context, format, and structure behind the exam. Describe the topics covered in the exam. Recognize the different types of questions provided on the exam. Identify resources that can be used to learn the material covered in the exam. Prerequisites Describe how to use and the benefits of the Databricks platform and developer tools Build optimized and cleaned data processing pipelines using the Spark and Delta Lake APIs Model data into a Lakehouse using knowledge of general data modeling concepts Ensure data pipelines secure, reliable, monitored, and tested before deployment Learning path This course is part of the Data Engineer learning path. Last course update July 2022
E-Learning Duration: 1h
Exam Information: Databricks Certified Professional Data Engineer (available for additional fee)